{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -U git+https://github.com/huggingface/transformers.git "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install torch torchvision torchaudio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install trl\n",
    "!pip install -U accelerate\n",
    "!pip install -U transformers\n",
    "!pip install peft\n",
    "!pip install utils\n",
    "!pip install transformers\n",
    "!pip install -U bitsandbytes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_csv=pd.read_csv('/mnt/DATA/Dhanvin/ML_CHALL/student_resource 3/dataset/train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_csv_modified=train_csv.drop(['group_id'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_csv_modified.rename(columns = {'entity_name':'question','entity_value':'answer'}, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_csv_modified"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_train_ds():\n",
    "    ds_arr=[]\n",
    "    for i in range(2110):\n",
    "        ds_dict={'image_link':train_csv_modified['image_link'][i],\n",
    "                  'question':train_csv_modified['question'][i], \n",
    "                  'answer':train_csv_modified['answer'][i]}\n",
    "        ds_arr.append(ds_dict)\n",
    "    return ds_arr\n",
    "\n",
    "def generate_test_ds():\n",
    "    ds_arr_1=[]\n",
    "    for i in range(528):\n",
    "        ds_dict={'image_link':train_csv_modified['image_link'][63325+i],\n",
    "                  'question':train_csv_modified['question'][63325+i], \n",
    "                  'answer':train_csv_modified['answer'][63325+i]}\n",
    "        ds_arr_1.append(ds_dict)\n",
    "    return ds_arr_1\n",
    "\n",
    "train_ds=generate_train_ds()\n",
    "eval_ds=generate_test_ds()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import PaliGemmaProcessor, PaliGemmaForConditionalGeneration, BitsAndBytesConfig, Trainer\n",
    "from PIL import Image\n",
    "import requests\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from PIL import Image\n",
    "# from io import BytesIO\n",
    "# import requests\n",
    "# # import urlopen\n",
    "# # Image.open(urlopen(train_csv['image_link'][0]))\n",
    "# for i in range(len(train_ds)):\n",
    "#     try:\n",
    "\n",
    "#         response = requests.get(train_ds[i]['image_link'])\n",
    "#         img = Image.open(BytesIO(response.content))\n",
    "#     except:\n",
    "#         train_ds.remove(train_ds[i])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggingface_hub import login\n",
    "\n",
    "# Read the token from the file\n",
    "with open(\"token.txt\", \"r\") as file:\n",
    "    hf_token = file.read().strip()\n",
    "\n",
    "# Log in to Hugging Face using the token\n",
    "login(token=hf_token)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_id = \"google/paligemma-3b-pt-224\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_quant_type=\"nf4\",\n",
    "    bnb_4bit_compute_dtype=torch.bfloat16\n",
    ")\n",
    "device=\"cuda\"\n",
    "model = PaliGemmaForConditionalGeneration.from_pretrained(\n",
    "    model_id,\n",
    "    quantization_config=bnb_config,\n",
    ").to(device)\n",
    "\n",
    "processor = PaliGemmaProcessor.from_pretrained(model_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_token = processor.tokenizer.convert_tokens_to_ids(\"<image>\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "from io import BytesIO\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def collate_fn(examples):\n",
    "#   texts = ['Extract'+example[\"question\"]+' from the image' for example in examples]\n",
    "#   images = [Image.open(BytesIO(requests.get(example['image_link']).content)).convert(\"RGB\").resize((224,224)) for example in examples]\n",
    "#   tokens = processor(text=texts, images=images,\n",
    "#                     return_tensors=\"pt\", padding=\"longest\",\n",
    "#                     tokenize_newline_separately=False)\n",
    "#   labels = tokens[\"input_ids\"]\n",
    "#   labels[labels == image_token] = -100\n",
    "#   tokens[\"labels\"] = labels\n",
    "#   return tokens\n",
    "import numpy as np\n",
    "def collate_fn(examples):\n",
    "    texts=[]\n",
    "    labels=[]\n",
    "    images=[]\n",
    "    for example in examples:\n",
    "        try:\n",
    "\n",
    "            img = Image.open(BytesIO(requests.get(example['image_link']).content)).convert(\"RGB\").resize((224,224))\n",
    "            np.array(img)\n",
    "            texts.append('Extract'+example[\"question\"]+' from the image')\n",
    "            labels.append(example['answer'])\n",
    "        \n",
    "            images.append(Image.open(BytesIO(requests.get(example['image_link']).content)).convert(\"RGB\").resize((224,224)))\n",
    "            \n",
    "        except:\n",
    "            continue\n",
    "\n",
    "    tokens = processor(text=texts, images=images, suffix=labels,\n",
    "                            return_tensors=\"pt\", padding=\"longest\",\n",
    "                            tokenize_newline_separately=False)\n",
    "    tokens = tokens.to(device)\n",
    "    return tokens\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from peft import get_peft_model, LoraConfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lora_config = LoraConfig(\n",
    "    r=8,\n",
    "    target_modules=[\"q_proj\", \"o_proj\", \"k_proj\", \"v_proj\", \"gate_proj\", \"up_proj\", \"down_proj\"],\n",
    "    task_type=\"CAUSAL_LM\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = get_peft_model(model, lora_config)\n",
    "model.print_trainable_parameters()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TrainingArguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "args=TrainingArguments(\n",
    "            num_train_epochs=2,\n",
    "            per_device_train_batch_size=2,\n",
    "            gradient_accumulation_steps=4,\n",
    "            warmup_steps=2,\n",
    "            learning_rate=2e-5,\n",
    "            weight_decay=1e-6,\n",
    "            adam_beta2=0.999,\n",
    "            logging_steps=20,\n",
    "            optim=\"adamw_hf\",\n",
    "            save_strategy=\"steps\",\n",
    "            save_steps=50,\n",
    "            push_to_hub=False,\n",
    "            save_total_limit=1,\n",
    "            remove_unused_columns=False,\n",
    "            output_dir='./model_checkpoints',\n",
    "            dataloader_pin_memory=False\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from trl import SFTTrainer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = SFTTrainer(\n",
    "    model=model,\n",
    "    args=args,\n",
    "\n",
    "    dataset_text_field=\"text\",\n",
    "    peft_config=lora_config,\n",
    "    train_dataset=train_ds,\n",
    "    eval_dataset=eval_ds,\n",
    "    data_collator=collate_fn,\n",
    "    dataset_kwargs={\"skip_prepare_dataset\": True}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.train()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dhanvin",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
